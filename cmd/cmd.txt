CUDA_VISIBLE_DEVICES=0 python -W ignore -u train_search.py \
	--img_root "/home/moon/tiny-imagenet-200" \
	--train_list "/home/moon/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/moon/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 16 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 200 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 0.5 \
	--note "TF-NAS-lam0.1-lat15.0-gpu" \
	--memory_lookup_path "./latency_pkl/peak_memory_yamae.pkl"

CUDA_VISIBLE_DEVICES=1 python -W ignore -u train_search.py \
	--img_root "/home/moon/tiny-imagenet-200" \
	--train_list "/home/moon/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/moon/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 16 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 200 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 3.0 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"



---------------------------------------------------------------------


CUDA_VISIBLE_DEVICES=1 python -W ignore -u train_search.py \
	--img_root "/home/dy/tiny-imagenet-200" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 16 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 200 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 3.0 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"


CUDA_VISIBLE_DEVICES=0 python -W ignore -u train_search.py \
	--img_root "/home/dy/tiny-imagenet-200" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 16 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 200 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 3.0 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"\
	

CUDA_VISIBLE_DEVICES=1 python -W ignore -u train_search.py \
	--img_root "/home/dy/tiny-imagenet-200" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 64 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 200 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 3.0 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"

CUDA_VISIBLE_DEVICES=1 python -W ignore -u train_search.py \
	--img_root "/home/dy/tiny-imagenet-200" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 64 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 200 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 3.0 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"

# cifar-10
CUDA_VISIBLE_DEVICES=1 python -W ignore -u train_search.py \
	--img_root "/home/dy/tiny-imagenet-200" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 32 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 10 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 0.5 \
	--note "TF-NAS-lam0.1-lat15.0-gpu" \
	--memory_lookup_path "./latency_pkl/peak_memory_yamae.pkl"


CUDA_VISIBLE_DEVICES=0 python -W ignore -u train_search.py \
	--img_root "/home/dy/tiny-imagenet-200" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--lookup_path "./latency_pkl/latency_gpu.pkl" \
	--save "./checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 90 \
	--batch_size 32 \
	--w_lr 0.025 \
	--w_mom 0.9 \
	--w_wd 1e-5 \
	--a_lr 0.01 \
	--a_wd 5e-4 \
	--grad_clip 5.0 \
	--T 5.0 \
	--T_decay 0.96 \
	--num_classes 10 \
	--lambda_lat 0.1 \
	--target_lat 15.0 \
	--target_memory 0.3125 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"





----evaluate the architecture----

CUDA_VISIBLE_DEVICES=0,1 python -u train_eval.py \
	--train_root "/home/moon/tiny-imagenet-200/train" \
	--val_root "/home/moon/tiny-imagenet-200/val" \
	--train_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/dy/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
	--model_path "./checkpoints/search-20220504-172320-TF-NAS-lam0.1-lat15.0-gpu/searched_model_11.pth.tar"

CUDA_VISIBLE_DEVICES=1 python -W ignore -u train_eval.py \
	--train_root "/home/moon/tiny-imagenet-200" \
    --val_root "/home/moon/tiny-imagenet-200" \
	--train_list "/home/moon/tiny-imagenet-200/tinyImageNet-100-trainlist.txt" \
	--val_list "/home/moon/tiny-imagenet-200/tinyImageNet-100-vallist.txt" \
    --model_path "./checkpoints/search-20220504-172320-TF-NAS-lam0.1-lat15.0-gpu/searched_model_56.pth.tar" \
	--save "./eval_checkpoints" \
	--print_freq 100 \
	--workers 4 \
	--epochs 500 \
	--batch_size 16 \
	--lr 0.025 \
	--momentum 0.9 \
	--grad_clip 5.0 \
	--num_classes 200 \
	--note "TF-NAS-lam0.1-lat15.0-gpu"
